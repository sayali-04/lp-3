{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0faedce-514c-46c9-b446-66d77f9a7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4415ce41-454f-4bb2-b8c1-ec92b1f0bba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Email No.', 'the', 'to', 'ect', 'and', 'for', 'of', 'a', 'you', 'hou',\n",
      "       ...\n",
      "       'connevey', 'jay', 'valued', 'lay', 'infrastructure', 'military',\n",
      "       'allowing', 'ff', 'dry', 'Prediction'],\n",
      "      dtype='object', length=3002)\n",
      "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
      "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
      "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
      "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
      "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
      "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
      "\n",
      "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0       0    0               0         0         0   0    0           0  \n",
      "1       0    0               0         0         0   1    0           0  \n",
      "2       0    0               0         0         0   0    0           0  \n",
      "3       0    0               0         0         0   0    0           0  \n",
      "4       0    0               0         0         0   1    0           0  \n",
      "\n",
      "[5 rows x 3002 columns]\n",
      "Prediction\n",
      "0    3672\n",
      "1    1500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.head())\n",
    "print(df['Prediction'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d012d39-ad0a-4e9b-834b-295164414185",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns= ['Prediction','Email No.'])\n",
    "y = df['Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c9852e-da30-485d-8555-edacf188826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_test , y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01640ce0-44dc-4ab4-8f0d-24ed22bcd4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------svc----------\n",
      "accuracy:  0.8628019323671497\n",
      "confusion matrix: \n",
      " [[646  93]\n",
      " [ 49 247]]\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       739\n",
      "           1       0.73      0.83      0.78       296\n",
      "\n",
      "    accuracy                           0.86      1035\n",
      "   macro avg       0.83      0.85      0.84      1035\n",
      "weighted avg       0.87      0.86      0.87      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score , confusion_matrix\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train,y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"-------svc----------\")\n",
    "print(\"accuracy: \", accuracy_score(y_test,knn_pred))\n",
    "print(\"confusion matrix: \\n\", confusion_matrix(y_test,knn_pred))\n",
    "print(\"classification report: \\n\", classification_report(y_test,knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32349604-f843-4430-9a93-66da95840d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------svc----------\n",
      "accuracy:  0.9594202898550724\n",
      "confusion matrix: \n",
      " [[715  24]\n",
      " [ 18 278]]\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       739\n",
      "           1       0.92      0.94      0.93       296\n",
      "\n",
      "    accuracy                           0.96      1035\n",
      "   macro avg       0.95      0.95      0.95      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"-------svc----------\")\n",
    "print(\"accuracy: \", accuracy_score(y_test,svm_pred))\n",
    "print(\"confusion matrix: \\n\", confusion_matrix(y_test,svm_pred))\n",
    "print(\"classification report: \\n\", classification_report(y_test,svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad3ef3-0a6e-4286-b2d8-3e69063e224e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
